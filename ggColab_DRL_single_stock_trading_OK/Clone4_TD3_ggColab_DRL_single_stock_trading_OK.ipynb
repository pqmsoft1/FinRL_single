{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clone4_TD3_ggColab_DRL_single_stock_trading_OK.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiCYf1Tm97ai"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFEQZoKIGZHa"
      },
      "source": [
        "## Clone code from ggColab_DRL_single_stock_trading_OK.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPZSlrCfGZvy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yM71W6T49_i5",
        "outputId": "1e9e3e11-ae98-4408-a748-e41e53081b72"
      },
      "source": [
        "!pip uninstall -y tensorflow==2.6.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.6.0\n",
            "Uninstalling tensorflow-2.6.0:\n",
            "  Successfully uninstalled tensorflow-2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIdpnjWI9_nK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Wq86rPPE9_pq",
        "outputId": "1dfafb36-af8f-4381-d0db-7686423d355d"
      },
      "source": [
        "import pkg_resources\n",
        "import pip\n",
        "installedPackages = {pkg.key for pkg in pkg_resources.working_set}\n",
        "required = {'yfinance', 'pandas', 'matplotlib', 'stockstats','stable-baselines','gym','tensorflow'}\n",
        "missing = required - installedPackages\n",
        "if missing:\n",
        "    !pip install yfinance\n",
        "    !pip install pandas\n",
        "    !pip install matplotlib\n",
        "    !pip install stockstats\n",
        "    !pip install gym\n",
        "    !pip install stable-baselines[mpi]\n",
        "    !pip install tensorflow==1.15.4"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.63.tar.gz (26 kB)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.23.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.9)\n",
            "Collecting lxml>=4.5.1\n",
            "  Downloading lxml-4.6.3-cp37-cp37m-manylinux2014_x86_64.whl (6.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.3 MB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24->yfinance) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (1.24.3)\n",
            "Building wheels for collected packages: yfinance\n",
            "  Building wheel for yfinance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yfinance: filename=yfinance-0.1.63-py2.py3-none-any.whl size=23918 sha256=78d2bb260384fa84b18344c64abfac05a83a1ae5b2116cdea6ecef8776c97b08\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/87/8b/7ec24486e001d3926537f5f7801f57a74d181be25b11157983\n",
            "Successfully built yfinance\n",
            "Installing collected packages: lxml, yfinance\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "Successfully installed lxml-4.6.3 yfinance-0.1.63\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
            "Collecting stockstats\n",
            "  Downloading stockstats-0.3.2-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.7/dist-packages (from stockstats) (1.19.5)\n",
            "Collecting int-date>=0.1.7\n",
            "  Downloading int_date-0.1.8-py2.py3-none-any.whl (5.0 kB)\n",
            "Requirement already satisfied: pandas>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from stockstats) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.4.2 in /usr/local/lib/python3.7/dist-packages (from int-date>=0.1.7->stockstats) (2.8.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from int-date>=0.1.7->stockstats) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18.1->stockstats) (2018.9)\n",
            "Installing collected packages: int-date, stockstats\n",
            "Successfully installed int-date-0.1.8 stockstats-0.3.2\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n",
            "Collecting stable-baselines[mpi]\n",
            "  Downloading stable_baselines-2.10.2-py3-none-any.whl (240 kB)\n",
            "\u001b[K     |████████████████████████████████| 240 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]) (4.1.2.30)\n",
            "Requirement already satisfied: gym[atari,classic_control]>=0.11 in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]) (0.17.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]) (1.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]) (1.0.1)\n",
            "Requirement already satisfied: cloudpickle>=0.5.5 in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]) (1.1.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]) (3.2.2)\n",
            "Collecting mpi4py\n",
            "  Downloading mpi4py-3.1.1.tar.gz (2.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 48.7 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]) (1.5.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]) (7.1.2)\n",
            "Requirement already satisfied: atari-py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]) (0.2.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from atari-py~=0.2.0->gym[atari,classic_control]>=0.11->stable-baselines[mpi]) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari,classic_control]>=0.11->stable-baselines[mpi]) (0.16.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines[mpi]) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines[mpi]) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines[mpi]) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines[mpi]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->stable-baselines[mpi]) (2018.9)\n",
            "Building wheels for collected packages: mpi4py\n",
            "  Building wheel for mpi4py (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-3.1.1-cp37-cp37m-linux_x86_64.whl size=2180656 sha256=ea284fa2f4b92ff81163e73c0daf692db12a845fa1dd5f4bc3a1860c7b85fa18\n",
            "  Stored in directory: /root/.cache/pip/wheels/91/be/c0/2b0347be1de5cd8ca9fe67da7ec8c3fe8930fcb6b0df6f2255\n",
            "Successfully built mpi4py\n",
            "Installing collected packages: stable-baselines, mpi4py\n",
            "Successfully installed mpi4py-3.1.1 stable-baselines-2.10.2\n",
            "Collecting tensorflow==1.15.4\n",
            "  Downloading tensorflow-1.15.4-cp37-cp37m-manylinux2010_x86_64.whl (110.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5 MB 47 kB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4) (1.12.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4) (1.40.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4) (0.37.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4) (0.12.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4) (3.17.3)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4) (1.15.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 56.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4) (0.2.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4) (0.8.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4) (3.3.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 39.2 MB/s \n",
            "\u001b[?25hCollecting numpy<1.19.0,>=1.16.0\n",
            "  Downloading numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.4) (3.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4) (3.3.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4) (4.8.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.4) (1.5.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4) (3.7.4.3)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=464f95f2260735cba46d4da245db53cd8e947928f5259d1b34f200dd3aa34eb0\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: numpy, tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.6.0\n",
            "    Uninstalling tensorflow-estimator-2.6.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.6.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.6.0\n",
            "    Uninstalling tensorboard-2.6.0:\n",
            "      Successfully uninstalled tensorboard-2.6.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.13.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "kapre 0.3.5 requires tensorflow>=2.0.0, but you have tensorflow 1.15.4 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 numpy-1.18.5 tensorboard-1.15.0 tensorflow-1.15.4 tensorflow-estimator-1.15.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5tZhQCv0zx-",
        "outputId": "30cc9379-c1e2-4dfe-8f29-376ffb725564"
      },
      "source": [
        "!git clone https://github.com/pqmsoft1/FinRL_single.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'FinRL_single'...\n",
            "remote: Enumerating objects: 107, done.\u001b[K\n",
            "remote: Counting objects: 100% (107/107), done.\u001b[K\n",
            "remote: Compressing objects: 100% (91/91), done.\u001b[K\n",
            "remote: Total 107 (delta 27), reused 85 (delta 11), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (107/107), 7.96 MiB | 21.92 MiB/s, done.\n",
            "Resolving deltas: 100% (27/27), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xM8GBGX-8m9M",
        "outputId": "d4658b12-1e8b-41a1-ef01-bc51edf0c742"
      },
      "source": [
        "cd FinRL_single/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/FinRL_single\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2O1safkiA7MD",
        "outputId": "81c1ae5d-61bd-4014-827b-dd579cd6c06a"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clone1_ggColab_DRL_single_stock_trading_OK.ipynb\n",
            "Clone2_PPO_ggColab_DRL_single_stock_trading_OK.ipynb\n",
            "contributing.md\n",
            "DMaster.docx\n",
            "docker\n",
            "DRL_multiple_stock_trading.ipynb\n",
            "DRL_single_stock_trading.ipynb\n",
            "figs\n",
            "finrl\n",
            "FinRL_demo_docker.ipynb\n",
            "FinRL_ensemble_stock_trading_ICAIF_2020.ipynb\n",
            "FinRL_portfolio_allocation_NeurIPS_2020.ipynb\n",
            "FinRL_single.ipynb\n",
            "FinRL_single_stock_trading.ipynb\n",
            "FinRL_stock_trading_fundamental.ipynb\n",
            "FinRL_stock_trading_NeurIPS_2018.ipynb\n",
            "ggColab_DRL_single_stock_trading_OK\n",
            "ggColab_DRL_single_stock_trading_OK.ipynb\n",
            "LICENSE\n",
            "main.py\n",
            "notebooks\n",
            "README.md\n",
            "requirements.txt\n",
            "setup.py\n",
            "SingleStock.docx\n",
            "tests\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AKa-X7vA9AZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FM4T6qfr-MpS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yw8rc7-d-MsC",
        "outputId": "b4cce2c2-ee7c-406e-8eaf-052ecb11a4e5"
      },
      "source": [
        "import yfinance as yf\n",
        "from stockstats import StockDataFrame as Sdf\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import gym\n",
        "from stable_baselines import PPO2, DDPG, A2C, ACKTR, TD3\n",
        "from stable_baselines import DDPG\n",
        "from stable_baselines import A2C\n",
        "from stable_baselines import SAC\n",
        "from stable_baselines.common.vec_env import DummyVecEnv\n",
        "from stable_baselines.common.policies import MlpPolicy\n",
        "#Diable the warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "#stockerID = \"AMZN\"\n",
        "stockerID = \"MSFT\"\n",
        "#stockerID = \"TSLA\"\n",
        "stockerID =\"FDX\"\n",
        "stockerID =\"ABMD\"\n",
        "stockerID =\"ABT\"\n",
        "stockerID = \"AAP\"\n",
        "stockerID = \"ABBV\"\n",
        "stockerID = \"AAPL\"\n",
        "\n",
        "START_DATE_DATA = \"2009-01-01\"\n",
        "END_DATE_DATA = \"2021-09-20\"\n",
        "\n",
        "END_DATE_TRAIN_DATA = \"2019-09-01\"\n",
        "\n",
        "PATH_CSV_STOCK = stockerID + \".csv\"\n",
        "\n",
        "data_df = yf.download(stockerID, start=START_DATE_DATA, end=END_DATE_DATA)\n",
        "# reset the index, we want to use numbers instead of dates\n",
        "data_df=data_df.reset_index()\n",
        "# convert the column names to standardized names\n",
        "data_df.columns = ['datadate','open','high','low','close','adjcp','volume']\n",
        "# save the data to a csv file in your current folder\n",
        "#data_df.to_csv('AAPL_2009_2020.csv')\n",
        "#data_df.to_csv('FB_2009_2021.csv')\n",
        "data_df.to_csv(PATH_CSV_STOCK)\n",
        "# check missing data \n",
        "data_df.isnull().values.any()\n",
        "# calculate technical indicators like MACD\n",
        "stock = Sdf.retype(data_df.copy())\n",
        "# we need to use adjusted close price instead of close price\n",
        "stock['close'] = stock['adjcp']\n",
        "data_df['macd'] = stock['macd']\n",
        "# check missing data again\n",
        "data_df.isnull().values.any()\n",
        "# Note that I always use a copy of the original data to try it track step by step.\n",
        "data_clean = data_df.copy()\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gym.utils import seeding\n",
        "import gym\n",
        "from gym import spaces\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Global variables\n",
        "HMAX_NORMALIZE = 200\n",
        "INITIAL_ACCOUNT_BALANCE=100000\n",
        "STOCK_DIM = 1\n",
        "\n",
        "# transaction fee: 1/1000 reasonable percentage\n",
        "TRANSACTION_FEE_PERCENT = 0.001\n",
        "# REWARD_SCALING = 1e-3\n",
        "\n",
        "\n",
        "class SingleStockEnv(gym.Env):\n",
        "    \"\"\"A stock trading environment for OpenAI gym\"\"\"\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(self, df,day = 0):\n",
        "        #super(StockEnv, self).__init__()\n",
        "        # date increment\n",
        "        self.day = day\n",
        "        self.df = df\n",
        "        # action_space normalization and the shape is STOCK_DIM\n",
        "        self.action_space = spaces.Box(low = -1, high = 1,shape = (STOCK_DIM,)) \n",
        "        # Shape = 4: [Current Balance]+[prices]+[owned shares] +[macd] \n",
        "        self.observation_space = spaces.Box(low=0, high=np.inf, shape = (4,))\n",
        "        # load data from a pandas dataframe\n",
        "        self.data = self.df.loc[self.day,:]\n",
        "        # termination\n",
        "        self.terminal = False  \n",
        "        # save the total number of trades\n",
        "        self.trades = 0\n",
        "        # initalize state\n",
        "        self.state = [INITIAL_ACCOUNT_BALANCE] + \\\n",
        "                      [self.data.adjcp] + \\\n",
        "                      [0]*STOCK_DIM + \\\n",
        "                      [self.data.macd] \n",
        "        # initialize reward and cost\n",
        "        self.reward = 0\n",
        "        self.cost = 0\n",
        "        \n",
        "        # memorize the total value, total rewards\n",
        "        self.asset_memory = [INITIAL_ACCOUNT_BALANCE]\n",
        "        self.rewards_memory = []\n",
        "\n",
        "    def _sell_stock(self, index, action):\n",
        "        # perform sell action based on the sign of the action\n",
        "        if self.state[index+STOCK_DIM+1] > 0:\n",
        "            # update balance\n",
        "            self.state[0] += \\\n",
        "            self.state[index+1]*min(abs(action),self.state[index+STOCK_DIM+1]) * \\\n",
        "             (1- TRANSACTION_FEE_PERCENT)\n",
        "            # update held shares\n",
        "            self.state[index+STOCK_DIM+1] -= min(abs(action), self.state[index+STOCK_DIM+1])\n",
        "            # update transaction costs\n",
        "            self.cost +=self.state[index+1]*min(abs(action),self.state[index+STOCK_DIM+1]) * \\\n",
        "             TRANSACTION_FEE_PERCENT\n",
        "            self.trades+=1\n",
        "        else:\n",
        "            pass\n",
        "            \n",
        "    def _buy_stock(self, index, action):\n",
        "        # perform buy action based on the sign of the action\n",
        "        available_amount = self.state[0] // self.state[index+1]\n",
        "        #update balance\n",
        "        self.state[0] -= self.state[index+1]*min(available_amount, action)* \\\n",
        "                          (1+ TRANSACTION_FEE_PERCENT)\n",
        "        # update held shares\n",
        "        self.state[index+STOCK_DIM+1] += min(available_amount, action)\n",
        "        # update transaction costs\n",
        "        self.cost+=self.state[index+1]*min(available_amount, action)* \\\n",
        "                          TRANSACTION_FEE_PERCENT\n",
        "        self.trades+=1\n",
        "        \n",
        "    def step(self, actions):\n",
        "        self.terminal = self.day >= len(self.df.index.unique())-1\n",
        "\n",
        "        if self.terminal:\n",
        "            plt.plot(self.asset_memory,'r')\n",
        "            plt.savefig('account_value.png')\n",
        "            plt.close()\n",
        "            \n",
        "            end_total_asset = self.state[0]+ \\\n",
        "            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\n",
        "            print(\"previous_total_asset:{}\".format(self.asset_memory[0])) \n",
        "            print(\"end_total_asset:{}\".format(end_total_asset))\n",
        "            \n",
        "            df_total_value = pd.DataFrame(self.asset_memory)\n",
        "            df_total_value.to_csv('account_value.csv')\n",
        "            print(\"total_reward:{}\".format(self.state[0]+sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))- INITIAL_ACCOUNT_BALANCE ))\n",
        "            print(\"total_cost: \", self.cost)\n",
        "            print(\"total trades: \", self.trades)\n",
        "            \n",
        "            df_total_value.columns = ['account_value']\n",
        "            df_total_value['daily_return']=df_total_value.pct_change(1)\n",
        "            \n",
        "            if df_total_value['daily_return'].std()!=0:\n",
        "                sharpe = (252**0.5)*df_total_value['daily_return'].mean()/ \\\n",
        "                      df_total_value['daily_return'].std()\n",
        "                print(\"Sharpe: \",sharpe)\n",
        "            df_rewards = pd.DataFrame(self.rewards_memory)\n",
        "            df_rewards.to_csv('account_rewards.csv')\n",
        "            return self.state, self.reward, self.terminal,{}\n",
        "\n",
        "        else:\n",
        "            \n",
        "            # actions are the shares we need to buy, hold, or sell\n",
        "            actions = actions * HMAX_NORMALIZE\n",
        "            # calculate begining total asset\n",
        "            begin_total_asset = self.state[0]+ \\\n",
        "            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\n",
        "            \n",
        "            # perform buy or sell action\n",
        "            argsort_actions = np.argsort(actions)\n",
        "            sell_index = argsort_actions[:np.where(actions < 0)[0].shape[0]]\n",
        "            buy_index = argsort_actions[::-1][:np.where(actions > 0)[0].shape[0]]\n",
        "\n",
        "            for index in sell_index:\n",
        "                # print('take sell action'.format(actions[index]))\n",
        "                self._sell_stock(index, actions[index])\n",
        "\n",
        "            for index in buy_index:\n",
        "                # print('take buy action: {}'.format(actions[index]))\n",
        "                self._buy_stock(index, actions[index])\n",
        "            \n",
        "            # update data, walk a step s'\n",
        "            self.day += 1\n",
        "            self.data = self.df.loc[self.day,:]         \n",
        "            #load next state\n",
        "            self.state =  [self.state[0]] + \\\n",
        "                          [self.data.adjcp] + \\\n",
        "                          list(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]) +\\\n",
        "                          [self.data.macd]\n",
        "                        \n",
        "            # calculate the end total asset\n",
        "            end_total_asset = self.state[0]+ \\\n",
        "            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\n",
        "            self.reward = end_total_asset - begin_total_asset  \n",
        "            self.rewards_memory.append(self.reward)\n",
        "            #self.reward = self.reward * REWARD_SCALING\n",
        "            self.asset_memory.append(end_total_asset)\n",
        "\n",
        "        return self.state, self.reward, self.terminal, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.asset_memory = [INITIAL_ACCOUNT_BALANCE]\n",
        "        self.day = 0\n",
        "        self.data = self.df.loc[self.day,:]\n",
        "        self.cost = 0\n",
        "        self.trades = 0\n",
        "        self.terminal = False \n",
        "        self.rewards_memory = []\n",
        "        #initiate state\n",
        "        self.state = [INITIAL_ACCOUNT_BALANCE] + \\\n",
        "                      [self.data.adjcp] + \\\n",
        "                      [0]*STOCK_DIM + \\\n",
        "                      [self.data.macd]\n",
        "        return self.state\n",
        "    \n",
        "    def render(self, mode='human'):\n",
        "        return self.state\n",
        "\n",
        "    def _seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]\n",
        "\n",
        "\n",
        "train = data_clean[(data_clean.datadate>=START_DATE_DATA) & (data_clean.datadate < END_DATE_TRAIN_DATA)]\n",
        "# the index needs to start from 0\n",
        "train=train.reset_index(drop=True)\n",
        "\n",
        "## Model Training: 4 models, PPO A2C, DDPG, TD3\n",
        "\n",
        "\n",
        "'''\n",
        "## Model 1: PPO\n",
        "\n",
        "#tensorboard --logdir ./single_stock_tensorboard/\n",
        "env_train = DummyVecEnv([lambda: SingleStockEnv(train)])\n",
        "model_ppo = PPO2('MlpPolicy', env_train, tensorboard_log=\"./single_stock_trading_2_tensorboard/\")\n",
        "model_ppo.learn(total_timesteps=100000,tb_log_name=\"run_aapl_ppo\")\n",
        "#model_ppo.save('AAPL_ppo_100k')\n",
        "#model_ppo.save('AAPL_ppo_100k')\n",
        "#model_sticker_save = 'FB_ppo_100k'\n",
        "model_sticker_save = model_sticker_save = stockerID + '_PPO_100k'\n",
        "model_ppo.save(model_sticker_save)\n",
        "\n",
        "\n",
        "\n",
        "env_train = DummyVecEnv([lambda: SingleStockEnv(train)])\n",
        "model_ppo = PPO2('MlpPolicy', env_train, tensorboard_log=\"./single_stock_trading_2_tensorboard/\")\n",
        "#model_ppo.load('AAPL_ppo_100k.zip')\n",
        "model_ppo.load(model_sticker_save)\n",
        "\n",
        "'''\n",
        "\n",
        "model_sticker_save = stockerID + '_TD3_100k'\n",
        "#tensorboard --logdir ./single_stock_tensorboard/\n",
        "#DQN<DDPG<TD3\n",
        "env_train = DummyVecEnv([lambda: SingleStockEnv(train)])\n",
        "model_td3 = TD3('MlpPolicy', env_train, tensorboard_log=\"./single_stock_trading_2_tensorboard/\")\n",
        "#model_td3.learn(total_timesteps=100000,tb_log_name=\"run_aapl_td3\")\n",
        "#model_td3.save('AAPL_td3_50k')\n",
        "model_td3.learn(total_timesteps=100000,tb_log_name=\"run_aapl_td3\")\n",
        "#model_td3.save('AAPL_td3_50k')\n",
        "model_td3.save(model_sticker_save)\n",
        "\n",
        "\n",
        "env_train = DummyVecEnv([lambda: SingleStockEnv(train)])\n",
        "model_td3 = TD3('MlpPolicy', env_train, tensorboard_log=\"./single_stock_trading_2_tensorboard/\")\n",
        "#model_td3.load('AAPL_td3_50k.zip')\n",
        "\n",
        "model_td3.load(model_sticker_save)\n",
        "\n",
        "\n",
        "# Trading\n",
        "# Assume that we have $100,000 initial capital at 2019-01-01. We use the TD3 model to trade AAPL.\n",
        "## sau khi chay xong: create file account_rewards.csv, account_value.csv, account_value.png \n",
        "\n",
        "\n",
        "test = data_clean[(data_clean.datadate >= END_DATE_TRAIN_DATA) ]\n",
        "# the index needs to start from 0\n",
        "test=test.reset_index(drop=True)\n",
        "\n",
        "\n",
        "#model = model_a2c\n",
        "#model = model_ppo\n",
        "model = model_td3\n",
        "#model = model_ddpg\n",
        "env_test = DummyVecEnv([lambda: SingleStockEnv(test)])\n",
        "obs_test = env_test.reset()\n",
        "print(\"==============Model Prediction===========\")\n",
        "for i in range(len(test.index.unique())):\n",
        "    action, _states = model.predict(obs_test)\n",
        "    obs_test, rewards, dones, info = env_test.step(action)\n",
        "    env_test.render()\n",
        "\n",
        "#==> Create file account_rewards.csv, account_value.csv, account_value.png sau khi chay xong\n",
        "\n",
        "\n",
        "'''\n",
        "Part 5: Backtest Our Strategy\n",
        "For simplicity purposes, in the article, we just calculate the Sharpe ratio and the annual return manually.\n",
        "'''\n",
        "\n",
        "\n",
        "def get_DRL_sharpe():\n",
        "    df_total_value=pd.read_csv('account_value.csv',index_col=0)\n",
        "    df_total_value.columns = ['account_value']\n",
        "    df_total_value['daily_return']=df_total_value.pct_change(1)\n",
        "    sharpe = (252**0.5)*df_total_value['daily_return'].mean()/ \\\n",
        "    df_total_value['daily_return'].std()\n",
        "    \n",
        "    annual_return = ((df_total_value['daily_return'].mean()+1)**252-1)*100\n",
        "    print(\"annual return: \", annual_return)\n",
        "    print(\"sharpe ratio: \", sharpe)\n",
        "    return df_total_value\n",
        "\n",
        "\n",
        "def get_buy_and_hold_sharpe(test):\n",
        "    test['daily_return']=test['adjcp'].pct_change(1)\n",
        "    sharpe = (252**0.5)*test['daily_return'].mean()/ \\\n",
        "    test['daily_return'].std()\n",
        "    annual_return = ((test['daily_return'].mean()+1)**252-1)*100\n",
        "    print(\"annual return: \", annual_return)\n",
        "\n",
        "    print(\"sharpe ratio: \", sharpe)\n",
        "    #return sharpe\n",
        "\n",
        "df_total_value=get_DRL_sharpe()\n",
        "get_buy_and_hold_sharpe(test)\n",
        "DRL_cumulative_return = (df_total_value.account_value.pct_change(1)+1).cumprod()-1\n",
        "buy_and_hold_cumulative_return = (test.adjcp.pct_change(1)+1).cumprod()-1\n",
        "\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "plt.plot(test.datadate, DRL_cumulative_return, color='red',label = \"DRL\")\n",
        "plt.plot(test.datadate, buy_and_hold_cumulative_return, label = \"Buy & Hold\")\n",
        "plt.title(\"Cumulative Return for AAPL with Transaction Cost\",size= 20)\n",
        "plt.legend()\n",
        "plt.rc('legend',fontsize=15)\n",
        "plt.rc('xtick', labelsize=15)\n",
        "plt.rc('ytick', labelsize=15)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n",
            "previous_total_asset:100000\n",
            "end_total_asset:1058450.5471891807\n",
            "total_reward:958450.5471891807\n",
            "total_cost:  121.5279503754815\n",
            "total trades:  2674\n",
            "Sharpe:  1.008088055649877\n",
            "previous_total_asset:100000\n",
            "end_total_asset:1444563.884409069\n",
            "total_reward:1344563.884409069\n",
            "total_cost:  99.89727962112428\n",
            "total trades:  2683\n",
            "Sharpe:  1.1109890842963628\n",
            "previous_total_asset:100000\n",
            "end_total_asset:1444563.884409069\n",
            "total_reward:1344563.884409069\n",
            "total_cost:  99.89727962112428\n",
            "total trades:  2683\n",
            "Sharpe:  1.1109890842963628\n",
            "previous_total_asset:100000\n",
            "end_total_asset:1444563.884409069\n",
            "total_reward:1344563.884409069\n",
            "total_cost:  99.89727962112428\n",
            "total trades:  2683\n",
            "Sharpe:  1.1109890842963628\n",
            "previous_total_asset:100000\n",
            "end_total_asset:1444563.884409069\n",
            "total_reward:1344563.884409069\n",
            "total_cost:  99.89727962112428\n",
            "total trades:  2683\n",
            "Sharpe:  1.1109890842963628\n",
            "previous_total_asset:100000\n",
            "end_total_asset:1444563.884409069\n",
            "total_reward:1344563.884409069\n",
            "total_cost:  99.89727962112428\n",
            "total trades:  2683\n",
            "Sharpe:  1.1109890842963628\n",
            "previous_total_asset:100000\n",
            "end_total_asset:1444563.884409069\n",
            "total_reward:1344563.884409069\n",
            "total_cost:  99.89727962112428\n",
            "total trades:  2683\n",
            "Sharpe:  1.1109890842963628\n",
            "previous_total_asset:100000\n",
            "end_total_asset:1444563.884409069\n",
            "total_reward:1344563.884409069\n",
            "total_cost:  99.89727962112428\n",
            "total trades:  2683\n",
            "Sharpe:  1.1109890842963628\n",
            "previous_total_asset:100000\n",
            "end_total_asset:1444563.884409069\n",
            "total_reward:1344563.884409069\n",
            "total_cost:  99.89727962112428\n",
            "total trades:  2683\n",
            "Sharpe:  1.1109890842963628\n",
            "previous_total_asset:100000\n",
            "end_total_asset:1444563.884409069\n",
            "total_reward:1344563.884409069\n",
            "total_cost:  99.89727962112428\n",
            "total trades:  2683\n",
            "Sharpe:  1.1109890842963628\n",
            "previous_total_asset:100000\n",
            "end_total_asset:1444563.884409069\n",
            "total_reward:1344563.884409069\n",
            "total_cost:  99.89727962112428\n",
            "total trades:  2683\n",
            "Sharpe:  1.1109890842963628\n",
            "previous_total_asset:100000\n",
            "end_total_asset:1444563.884409069\n",
            "total_reward:1344563.884409069\n",
            "total_cost:  99.89727962112428\n",
            "total trades:  2683\n",
            "Sharpe:  1.1109890842963628\n",
            "previous_total_asset:100000\n",
            "end_total_asset:1444563.884409069\n",
            "total_reward:1344563.884409069\n",
            "total_cost:  99.89727962112428\n",
            "total trades:  2683\n",
            "Sharpe:  1.1109890842963628\n",
            "previous_total_asset:100000\n",
            "end_total_asset:1444563.884409069\n",
            "total_reward:1344563.884409069\n",
            "total_cost:  99.89727962112428\n",
            "total trades:  2683\n",
            "Sharpe:  1.1109890842963628\n",
            "previous_total_asset:100000\n",
            "end_total_asset:1444563.884409069\n",
            "total_reward:1344563.884409069\n",
            "total_cost:  99.89727962112428\n",
            "total trades:  2683\n",
            "Sharpe:  1.1109890842963628\n",
            "previous_total_asset:100000\n",
            "end_total_asset:1444563.884409069\n",
            "total_reward:1344563.884409069\n",
            "total_cost:  99.89727962112428\n",
            "total trades:  2683\n",
            "Sharpe:  1.1109890842963628\n",
            "previous_total_asset:100000\n",
            "end_total_asset:1444563.884409069\n",
            "total_reward:1344563.884409069\n",
            "total_cost:  99.89727962112428\n",
            "total trades:  2683\n",
            "Sharpe:  1.1109890842963628\n",
            "previous_total_asset:100000\n",
            "end_total_asset:1444563.884409069\n",
            "total_reward:1344563.884409069\n",
            "total_cost:  99.89727962112428\n",
            "total trades:  2683\n",
            "Sharpe:  1.1109890842963628\n",
            "previous_total_asset:100000\n",
            "end_total_asset:1444563.884409069\n",
            "total_reward:1344563.884409069\n",
            "total_cost:  99.89727962112428\n",
            "total trades:  2683\n",
            "Sharpe:  1.1109890842963628\n",
            "previous_total_asset:100000\n",
            "end_total_asset:1444563.884409069\n",
            "total_reward:1344563.884409069\n",
            "total_cost:  99.89727962112428\n",
            "total trades:  2683\n",
            "Sharpe:  1.1109890842963628\n",
            "previous_total_asset:100000\n",
            "end_total_asset:1444563.884409069\n",
            "total_reward:1344563.884409069\n",
            "total_cost:  99.89727962112428\n",
            "total trades:  2683\n",
            "Sharpe:  1.1109890842963628\n",
            "previous_total_asset:100000\n",
            "end_total_asset:1444563.884409069\n",
            "total_reward:1344563.884409069\n",
            "total_cost:  99.89727962112428\n",
            "total trades:  2683\n",
            "Sharpe:  1.1109890842963628\n",
            "previous_total_asset:100000\n",
            "end_total_asset:1444563.884409069\n",
            "total_reward:1344563.884409069\n",
            "total_cost:  99.89727962112428\n",
            "total trades:  2683\n",
            "Sharpe:  1.1109890842963628\n",
            "previous_total_asset:100000\n",
            "end_total_asset:1444563.884409069\n",
            "total_reward:1344563.884409069\n",
            "total_cost:  99.89727962112428\n",
            "total trades:  2683\n",
            "Sharpe:  1.1109890842963628\n",
            "previous_total_asset:100000\n",
            "end_total_asset:1444563.884409069\n",
            "total_reward:1344563.884409069\n",
            "total_cost:  99.89727962112428\n",
            "total trades:  2683\n",
            "Sharpe:  1.1109890842963628\n",
            "previous_total_asset:100000\n",
            "end_total_asset:1444563.884409069\n",
            "total_reward:1344563.884409069\n",
            "total_cost:  99.89727962112428\n",
            "total trades:  2683\n",
            "Sharpe:  1.1109890842963628\n",
            "previous_total_asset:100000\n",
            "end_total_asset:1444563.884409069\n",
            "total_reward:1344563.884409069\n",
            "total_cost:  99.89727962112428\n",
            "total trades:  2683\n",
            "Sharpe:  1.1109890842963628\n",
            "previous_total_asset:100000\n",
            "end_total_asset:1444563.884409069\n",
            "total_reward:1344563.884409069\n",
            "total_cost:  99.89727962112428\n",
            "total trades:  2683\n",
            "Sharpe:  1.1109890842963628\n",
            "previous_total_asset:100000\n",
            "end_total_asset:1444563.884409069\n",
            "total_reward:1344563.884409069\n",
            "total_cost:  99.89727962112428\n",
            "total trades:  2683\n",
            "Sharpe:  1.1109890842963628\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cmg8TL0-rbT"
      },
      "source": [
        "## Model Training: 4 models, PPO A2C, DDPG, TD3\n",
        "## Model 1: PPO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1Ak9hVU-MuM"
      },
      "source": [
        "#tensorboard --logdir ./single_stock_tensorboard/\n",
        "env_train = DummyVecEnv([lambda: SingleStockEnv(train)])\n",
        "model_ppo = PPO2('MlpPolicy', env_train, tensorboard_log=\"./single_stock_trading_2_tensorboard/\")\n",
        "model_ppo.learn(total_timesteps=100000,tb_log_name=\"run_aapl_ppo\")\n",
        "#model_ppo.save('AAPL_ppo_100k')\n",
        "#model_ppo.save('AAPL_ppo_100k')\n",
        "#model_sticker_save = 'FB_ppo_100k'\n",
        "model_sticker_save = 'amzn_ppo_100k'\n",
        "model_ppo.save(model_sticker_save)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-o9vOq_-3Wi"
      },
      "source": [
        "## Model 2: DDPG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR_WNon2-Mwb"
      },
      "source": [
        "#tensorboard --logdir ./single_stock_tensorboard/\n",
        "env_train = DummyVecEnv([lambda: SingleStockEnv(train)])\n",
        "model_ddpg = DDPG('MlpPolicy', env_train, tensorboard_log=\"./single_stock_trading_2_tensorboard/\")\n",
        "#model_ddpg.learn(total_timesteps=100000, tb_log_name=\"run_aapl_ddpg\")\n",
        "#model_ddpg.save('AAPL_ddpg_50k')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERtTQEUS-Myr"
      },
      "source": [
        "model_ddpg.learn(total_timesteps=100000, tb_log_name=\"run_aapl_ddpg\")\n",
        "model_ddpg.save('AAPL_ddpg_50k')\n",
        "\n",
        "#model_ddpg.save(model_sticker_save)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbEwEVS5--xC"
      },
      "source": [
        "## Model 3: A2C"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqwECOAB-M1C"
      },
      "source": [
        "#tensorboard --logdir ./single_stock_tensorboard/\n",
        "env_train = DummyVecEnv([lambda: SingleStockEnv(train)])\n",
        "model_a2c = A2C('MlpPolicy', env_train, tensorboard_log=\"./single_stock_trading_2_tensorboard/\")\n",
        "model_a2c.learn(total_timesteps=100000,tb_log_name=\"run_aapl_a2c\")\n",
        "#model_a2c.save('AAPL_a2c_50k')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkXmJ0Bo9_r6"
      },
      "source": [
        "model_a2c.save('AAPL_a2c_50k')\n",
        "#model_a2c.save(model_sticker_save)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1T-oJfX_Ewq"
      },
      "source": [
        "## Model 4: TD3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swsevaDl_Cfh"
      },
      "source": [
        "#tensorboard --logdir ./single_stock_tensorboard/\n",
        "#DQN<DDPG<TD3\n",
        "env_train = DummyVecEnv([lambda: SingleStockEnv(train)])\n",
        "model_td3 = TD3('MlpPolicy', env_train, tensorboard_log=\"./single_stock_trading_2_tensorboard/\")\n",
        "#model_td3.learn(total_timesteps=100000,tb_log_name=\"run_aapl_td3\")\n",
        "#model_td3.save('AAPL_td3_50k')\n",
        "model_td3.learn(total_timesteps=100000,tb_log_name=\"run_aapl_td3\")\n",
        "model_td3.save('AAPL_td3_50k')\n",
        "#model_td3.save(model_sticker_save)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dk28SuRk_LuB"
      },
      "source": [
        "## Testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3897qQ8_Ch5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvg39bOe_QLx"
      },
      "source": [
        "## Load model from file save"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5vgJKZq_Qs5"
      },
      "source": [
        "## Load model PPO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vr377TvW_CkK"
      },
      "source": [
        "env_train = DummyVecEnv([lambda: SingleStockEnv(train)])\n",
        "model_ppo = PPO2('MlpPolicy', env_train, tensorboard_log=\"./single_stock_trading_2_tensorboard/\")\n",
        "#model_ppo.load('AAPL_ppo_100k.zip')\n",
        "model_ppo.load(model_sticker_save)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cPpuYQ9_YOS"
      },
      "source": [
        "## Load models a2c"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJoBO65D_CmZ"
      },
      "source": [
        "env_train = DummyVecEnv([lambda: SingleStockEnv(train)])\n",
        "model_a2c = A2C('MlpPolicy', env_train, tensorboard_log=\"./single_stock_trading_2_tensorboard/\")\n",
        "model_a2c.load(model_sticker_save)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiPeTYqe_dQZ"
      },
      "source": [
        "## Load model ddpg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KepzXkwn_CoZ"
      },
      "source": [
        "env_train = DummyVecEnv([lambda: SingleStockEnv(train)])\n",
        "model_ddpg = DDPG('MlpPolicy', env_train, tensorboard_log=\"./single_stock_trading_2_tensorboard/\")\n",
        "#model_ddpg.load('AAPL_ddpg_50k.zip')\n",
        "model_ddpg.load(model_sticker_save)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPauM4FM_jfq"
      },
      "source": [
        "## Load model td3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wH52_pwn_Cqa"
      },
      "source": [
        "env_train = DummyVecEnv([lambda: SingleStockEnv(train)])\n",
        "model_td3 = TD3('MlpPolicy', env_train, tensorboard_log=\"./single_stock_trading_2_tensorboard/\")\n",
        "model_td3.load('AAPL_td3_50k.zip')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuMp3IBr_nrq"
      },
      "source": [
        "# Trading\n",
        "Assume that we have $100,000 initial capital at 2019-01-01. We use the TD3 model to trade AAPL.\n",
        "\n",
        "## sau khi chay xong: create file account_rewards.csv, account_value.csv, account_value.png "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuHJ2FAf_lUy"
      },
      "source": [
        "\n",
        "test = data_clean[(data_clean.datadate >= END_DATE_TRAIN_DATA) ]\n",
        "# the index needs to start from 0\n",
        "test=test.reset_index(drop=True)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSONrBklFLf5"
      },
      "source": [
        "test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3cLrinGFJJC",
        "outputId": "17fb9013-9828-4947-9dd8-43c3d2d4480f"
      },
      "source": [
        "#model = model_a2c\n",
        "model = model_ppo\n",
        "#model = model_td3\n",
        "#model = model_ddpg\n",
        "env_test = DummyVecEnv([lambda: SingleStockEnv(test)])\n",
        "obs_test = env_test.reset()\n",
        "print(\"==============Model Prediction===========\")\n",
        "for i in range(len(test.index.unique())):\n",
        "    action, _states = model.predict(obs_test)\n",
        "    obs_test, rewards, dones, info = env_test.step(action)\n",
        "    env_test.render()\n",
        "\n",
        "#==> Create file account_rewards.csv, account_value.csv, account_value.png sau khi chay xong"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============Model Prediction===========\n",
            "previous_total_asset:100000\n",
            "end_total_asset:91214.80049134279\n",
            "total_reward:-8785.199508657213\n",
            "total_cost:  1216.9028415728942\n",
            "total trades:  52\n",
            "Sharpe:  -3.1096071839715838\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRy8w11h_rmy"
      },
      "source": [
        "## Part 5: Backtest Our Strategy\n",
        "For simplicity purposes, in the article, we just calculate the Sharpe ratio and the annual return manually."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xc2v1jpT_lXq",
        "outputId": "cafb6a75-311b-4066-8606-d63bb9ce40b3"
      },
      "source": [
        "\n",
        "def get_DRL_sharpe():\n",
        "    df_total_value=pd.read_csv('account_value.csv',index_col=0)\n",
        "    df_total_value.columns = ['account_value']\n",
        "    df_total_value['daily_return']=df_total_value.pct_change(1)\n",
        "    sharpe = (252**0.5)*df_total_value['daily_return'].mean()/ \\\n",
        "    df_total_value['daily_return'].std()\n",
        "    \n",
        "    annual_return = ((df_total_value['daily_return'].mean()+1)**252-1)*100\n",
        "    print(\"annual return: \", annual_return)\n",
        "    print(\"sharpe ratio: \", sharpe)\n",
        "    return df_total_value\n",
        "\n",
        "\n",
        "def get_buy_and_hold_sharpe(test):\n",
        "    test['daily_return']=test['adjcp'].pct_change(1)\n",
        "    sharpe = (252**0.5)*test['daily_return'].mean()/ \\\n",
        "    test['daily_return'].std()\n",
        "    annual_return = ((test['daily_return'].mean()+1)**252-1)*100\n",
        "    print(\"annual return: \", annual_return)\n",
        "\n",
        "    print(\"sharpe ratio: \", sharpe)\n",
        "    #return sharpe\n",
        "\n",
        "df_total_value=get_DRL_sharpe()\n",
        "get_buy_and_hold_sharpe(test)\n",
        "DRL_cumulative_return = (df_total_value.account_value.pct_change(1)+1).cumprod()-1\n",
        "buy_and_hold_cumulative_return = (test.adjcp.pct_change(1)+1).cumprod()-1\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "annual return:  -34.2962179054769\n",
            "sharpe ratio:  -3.1096071839715633\n",
            "annual return:  -50.82201630086771\n",
            "sharpe ratio:  -3.7496910745541077\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HmnT9KBJRpu"
      },
      "source": [
        "#DRL_cumulative_return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dps-hbmJ_lZ7"
      },
      "source": [
        "%matplotlib inline\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "plt.plot(test.datadate, DRL_cumulative_return, color='red',label = \"DRL\")\n",
        "plt.plot(test.datadate, buy_and_hold_cumulative_return, label = \"Buy & Hold\")\n",
        "plt.title(\"Cumulative Return for AAPL with Transaction Cost\",size= 20)\n",
        "plt.legend()\n",
        "plt.rc('legend',fontsize=15)\n",
        "plt.rc('xtick', labelsize=15)\n",
        "plt.rc('ytick', labelsize=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuX1LVRn_3cL"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('AAPL_a2c_50k.zip')\n",
        "files.download('AAPL_td3_50k.zip')\n",
        "files.download('AAPL_ppo_100k.zip')\n",
        "files.download('AAPL_ddpg_50k.zip')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}